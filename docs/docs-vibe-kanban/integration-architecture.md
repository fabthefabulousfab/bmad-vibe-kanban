# Integration Architecture

> Comprehensive analysis of how the 6 parts of bmad-vibe-kanban communicate and integrate
> Generated: 2026-02-17

---

## 1. Overview - System Communication Architecture

The bmad-vibe-kanban system is a polyglot monorepo with 6 distinct parts that integrate through multiple communication patterns:

```
┌─────────────────────────────────────────────────────────────────┐
│                    NPX CLI (Part 5)                             │
│  Downloads platform binary from Cloudflare R2                   │
└────────────────────┬────────────────────────────────────────────┘
                     │ Launches
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│              Local Server (Part 1: Rust Backend)                │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  crates/server (Axum HTTP Server)                        │   │
│  │         │                                                 │   │
│  │         ├──> crates/services (Business Logic)            │   │
│  │         │         │                                       │   │
│  │         │         ├──> crates/db (SQLite + EventHooks)   │   │
│  │         │         ├──> crates/git (Worktrees)            │   │
│  │         │         ├──> crates/executors (AI Agents)      │   │
│  │         │         └──> crates/deployment (Abstraction)   │   │
│  │         │                        │                        │   │
│  │         │                        └──> crates/local-deployment │
│  └──────────────────────────────────────────────────────────┘   │
│         │                     │                                  │
│         │ Embedded            │ Child Processes                  │
│         ▼                     ▼                                  │
│  Frontend (Part 2)     AI Coding Agents                         │
│  React SPA (Vite)      (Claude, Gemini, etc.)                   │
│         │                     │                                  │
│         │ Imports             │ JSONL Logs                       │
│         ▼                     │                                  │
│  shared/types.ts              │                                  │
│  (Generated by ts-rs)         │                                  │
└─────────────────────────────────────────────────────────────────┘
         │ HTTP/SSE/WS          │
         │                      │
         ▼                      ▼
┌─────────────────────────────────────────────────────────────────┐
│            Remote Server (Part 6: Cloud Backend)                │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  crates/remote (PostgreSQL + JWT Auth)                   │   │
│  │         │                                                 │   │
│  │         ├──> OAuth (GitHub, Google)                      │   │
│  │         ├──> Stripe Billing                              │   │
│  │         ├──> GitHub App Webhooks                         │   │
│  │         ├──> Electric SQL Proxy                          │   │
│  │         └──> Remote Frontend (Part 3: SaaS Portal)       │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

### Communication Summary

| From | To | Protocol | Purpose |
|------|-----|----------|---------|
| NPX CLI | Cloudflare R2 | HTTP | Binary distribution |
| Frontend | Local Server | HTTP REST | CRUD operations |
| Frontend | Local Server | SSE | Real-time execution logs, diffs, events |
| Frontend | Local Server | WebSocket | Terminal PTY, scratch pad |
| Frontend | Shared Types | TypeScript import | Type safety |
| Local Server | AI Agents | Child process stdio | Agent execution |
| Local Server | Git Repos | libgit2 (git2-rs) | Worktrees, branches, diffs |
| Local Server | Remote Server | HTTP REST | OAuth, PR sync, issue sync |
| Remote Server | PostgreSQL | SQLx pool | Data persistence |
| Remote Server | GitHub | GitHub App API | PR reviews, webhooks |
| Remote Server | Stripe | Stripe API | Billing |
| Remote Server | Electric SQL | HTTP proxy | Real-time sync to frontend |
| ts-rs Generator | Shared Types | File generation | Rust to TypeScript types |

---

## 2. Internal Integration (Rust Workspace)

### 2.1 Crate Dependency Graph

```
server (main binary)
├── deployment (trait abstraction)
│   ├── db
│   ├── services
│   ├── executors
│   ├── git
│   └── utils
├── local-deployment (concrete implementation)
│   ├── deployment
│   ├── db
│   ├── services
│   ├── executors
│   ├── git
│   └── utils
└── routes (HTTP handlers)

services (business logic layer)
├── db (data access)
├── executors (agent spawning)
├── git (operations)
└── utils (shared)

executors (9 AI agent implementations)
└── utils (as workspace_utils)

db (data layer - standalone)
├── sqlx
├── chrono
├── uuid
└── ts-rs

git (standalone git operations)
remote (separate cloud server)
review (standalone CLI tool)
utils (standalone utilities)
```

### 2.2 Deployment Trait - Service Locator Pattern

The `Deployment` trait (in `crates/deployment/src/lib.rs`) serves as the central service locator, defining access to all services:

```rust
#[async_trait]
pub trait Deployment: Clone + Send + Sync + 'static {
    async fn new() -> Result<Self, DeploymentError>;

    // Service accessors
    fn user_id(&self) -> &str;
    fn config(&self) -> &Arc<RwLock<Config>>;
    fn db(&self) -> &DBService;
    fn analytics(&self) -> &Option<AnalyticsService>;
    fn container(&self) -> &impl ContainerService;
    fn git(&self) -> &GitService;
    fn project(&self) -> &ProjectService;
    fn repo(&self) -> &RepoService;
    fn image(&self) -> &ImageService;
    fn filesystem(&self) -> &FilesystemService;
    fn events(&self) -> &EventService;
    fn file_search_cache(&self) -> &Arc<FileSearchCache>;
    fn approvals(&self) -> &Approvals;
    fn queued_message_service(&self) -> &QueuedMessageService;
    fn auth_context(&self) -> &AuthContext;
    fn remote_client(&self) -> Result<RemoteClient, RemoteClientNotConfigured>;

    // Provided methods
    async fn update_sentry_scope(&self) -> Result<(), DeploymentError>;
    async fn track_if_analytics_allowed(&self, event_name: &str, properties: Value);
    async fn trigger_auto_project_setup(&self);
    async fn stream_events(&self) -> BoxStream<'static, Result<Event, std::io::Error>>;
}
```

**Purpose**: This trait enables:
- Dependency injection without runtime overhead
- Swappable implementations (LocalDeployment vs future CloudDeployment)
- Centralized service access across all route handlers
- Type-safe service resolution

### 2.3 ServiceState as Dependency Injection Container

LocalDeployment (in `crates/local-deployment/src/lib.rs`) implements the Deployment trait and holds all service instances:

```rust
#[derive(Clone)]
pub struct LocalDeployment {
    user_id: String,
    config: Arc<RwLock<Config>>,
    db: DBService,
    analytics: Option<AnalyticsService>,
    container: Arc<LocalContainer>,
    git: GitService,
    project: ProjectService,
    repo: RepoService,
    image: ImageService,
    filesystem: FilesystemService,
    events: EventService,
    file_search_cache: Arc<FileSearchCache>,
    approvals: Approvals,
    queued_message_service: QueuedMessageService,
    auth_context: AuthContext,
    pty_service: PtyService,
}
```

**Initialization sequence** (from `crates/server/src/main.rs`):

1. Install rustls crypto provider
2. Initialize Sentry error monitoring
3. Configure tracing/logging
4. Create asset directory
5. **Create LocalDeployment** (instantiates all services, DB, background tasks)
6. Update Sentry scope with user context
7. Cleanup orphan execution processes
8. Backfill git metadata (before_head_commits, repo names)
9. Track analytics session_start event
10. Warm file search cache (async background task)
11. Build Axum router with LocalDeployment as state
12. Bind to port (auto-assign if PORT=0)
13. Write port file (production only)
14. Open browser (production only)
15. Serve with graceful shutdown (kills all running processes on exit)

### 2.4 Service Layer Organization

The `crates/services/src/services/` directory contains 27 service modules:

| Service | Responsibility |
|---------|----------------|
| `container_service` | Workspace lifecycle, execution process management, task finalization |
| `workspace_manager` | Creates workspace directories with git worktrees for all repos |
| `worktree_manager` | Low-level git worktree operations (create, remove, move) |
| `event_service` | Real-time event streaming via MsgStore, SSE/WebSocket patch delivery |
| `config` | Versioned JSON config (v8), editor settings, notifications, theme |
| `project` | Project CRUD, repository management, file search |
| `repo` | Repository CRUD, path validation, git repo detection |
| `filesystem` | Directory listing, file reading/writing, repo discovery |
| `file_search` | Cached file/directory search with git history ranking |
| `git_host` | GitHub and Azure DevOps PR management (create, status, comments) |
| `diff_stream` | DiffStats computation and real-time diff streaming |
| `analytics` | PostHog event tracking |
| `notification` | Cross-platform sound and push notifications |
| `approvals` | Tool call approval/rejection system for coding agents |
| `remote_client` | OAuth client for remote server communication |
| `auth` | Credential management (OAuth tokens, profile caching) |
| `oauth_credentials` | Persistent JWT token storage |
| `pr_monitor` | Background task polling PR status every 60s |
| `migration` | Data migration between local and remote servers |
| `queued_message` | Message queue for follow-up operations |
| `remote_sync` | Sync utilities for local to remote state |

---

## 3. Frontend-Backend Communication

### 3.1 HTTP REST API

**Base URL**: `/api`

**Frontend Client**: Fetch-based API client in `frontend/src/lib/api.ts`

**Type Safety**: All request/response types imported from `shared/types.ts` (auto-generated by ts-rs)

**Error Handling**:
```typescript
export class ApiError<E = unknown> extends Error {
  public status?: number;
  public error_data?: E;

  constructor(message: string, statusCode?: number, response?: Response, error_data?: E) {
    super(message);
    this.name = 'ApiError';
    this.status = statusCode;
    this.error_data = error_data;
  }
}
```

**API Response Format**:
```typescript
interface ApiResponse<T, E = unknown> {
  success: boolean;
  data?: T;
  error_data?: E;
  message?: string;
}
```

**Example API Namespaces**:
- `projectsApi` - CRUD, repository management, file search
- `tasksApi` - Task management, create-and-start
- `sessionsApi` - Session creation, follow-up, review
- `attemptsApi` (workspaces) - Workspace lifecycle, merge, PR, scripts
- `executionProcessesApi` - Process details, repo states, stop
- `fileSystemApi` - Directory listing, git repos
- `repoApi` - Repo CRUD, branches, open PRs
- `configApi` - User config, editor/agent availability
- `tagsApi` - Tag management
- `imagesApi` - Image upload, retrieval
- `approvalsApi` - Tool call approvals
- `oauthApi` - OAuth handoff, status, token management
- `organizationsApi` - Remote org management
- `scratchApi` - Scratch pad CRUD
- `queueApi` - Session follow-up queue
- `migrationApi` - Data migration

### 3.2 Server-Sent Events (SSE) Streams

**Purpose**: Unidirectional real-time updates from server to frontend

**SSE Endpoints**:

| Endpoint | Data Streamed | Frontend Usage |
|----------|---------------|----------------|
| `/api/execution-processes/:id/stream` | JSONL logs from agent execution | Real-time log display |
| `/api/execution-processes/:id/diff-stream` | Git diff statistics | Live diff updates |
| `/api/events` | Global event stream (JSON Patches) | Real-time UI updates |
| `/api/agents/slash-commands/ws` | Slash command discovery | Agent command autocomplete |

**Event Stream Architecture**:

```
SQLite INSERT/UPDATE
       │
       ▼
after_connect hook (EventService::register_event_listener)
       │
       ▼
JSON Patch generation
       │
       ▼
MsgStore.push(LogMsg::JsonPatch(patch))
       │
       ├──> history buffer (100MB limit, circular)
       └──> broadcast::Sender (10000 capacity)
              │
              ▼
        MsgStore.history_plus_stream()
              │
              ├──> Historical patches (on connect)
              └──> Live patches (broadcast stream)
                     │
                     ▼
              SSE Event stream to frontend
```

**MsgStore Implementation** (`crates/utils/src/msg_store.rs`):
- In-memory pub/sub with history
- Circular buffer with 100MB limit
- Broadcast channel with 10000 message capacity
- LogMsg variants: Stdout, Stderr, JsonPatch, SessionId, MessageId, Finished

### 3.3 WebSocket Connections

**Purpose**: Bidirectional real-time communication

**WebSocket Endpoints**:

| Endpoint | Purpose | Protocol |
|----------|---------|----------|
| `/api/terminal/ws` | PTY terminal sessions | xterm.js compatible |
| `/api/scratch/:type/:id/stream/ws` | Scratch pad sync | JSON Patch-based |

**Terminal PTY Flow**:
```
Frontend (xterm.js)
       │
       ▼
WebSocket /api/terminal/ws?workspace_id=X&cols=80&rows=24
       │
       ▼
PtyService spawns shell in workspace directory
       │
       ├──> stdin: from WebSocket messages
       └──> stdout/stderr: to WebSocket messages
              │
              ▼
        xterm.js renders terminal
```

**Scratch Pad WebSocket Flow**:
```
Frontend editor
       │
       ▼
WebSocket /api/scratch/:type/:id/stream/ws
       │
       ├──> Send JSON Patches (user edits)
       └──> Receive JSON Patches (server updates)
              │
              ▼
        SQLite scratch table updated
              │
              ▼
        Broadcast to all connected clients
```

### 3.4 Type Safety via ts-rs

**Build-time Type Generation**:

```
Rust structs with #[derive(TS)]
       │
       ▼
ts-rs type generator (crates/server/src/bin/generate_types.rs)
       │
       ▼
shared/types.ts (TypeScript definitions)
       │
       ▼
Frontend imports and uses types
```

**Example**:
```rust
// crates/db/src/models/project.rs
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export, export_to = "../../../shared/types.ts")]
pub struct Project {
    pub id: Uuid,
    pub name: String,
    pub default_agent_working_dir: Option<String>,
    pub remote_project_id: Option<Uuid>,
    pub created_at: String,
    pub updated_at: String,
}
```

Generated TypeScript:
```typescript
// shared/types.ts
export interface Project {
    id: string;
    name: string;
    default_agent_working_dir?: string;
    remote_project_id?: string;
    created_at: string;
    updated_at: string;
}
```

**Workflow**:
1. Developer modifies Rust struct
2. CI runs `cargo run --bin generate_types`
3. `shared/types.ts` updated automatically
4. TypeScript compiler catches frontend type mismatches
5. Zero runtime overhead, compile-time safety

---

## 4. Local-Remote Communication

### 4.1 OAuth Handoff Flow

**Purpose**: Local server delegates OAuth to remote server (has client secrets)

**Flow**:
```
1. Frontend: User clicks "Login with GitHub"
       │
       ▼
2. POST /api/auth/handoff/init { provider: "github", return_to: "http://localhost:53427" }
       │
       ▼
3. Local server forwards to Remote: POST /v1/oauth/handoff/init
       │
       ▼
4. Remote server creates handoff record, generates PKCE challenge
       │
       ▼
5. Remote returns: { handoff_id: "uuid", authorize_url: "https://github.com/login/oauth/authorize?..." }
       │
       ▼
6. Frontend opens authorize_url in browser
       │
       ▼
7. User authorizes on GitHub
       │
       ▼
8. GitHub redirects to Remote: /v1/oauth/callback?code=...&state=handoff_id
       │
       ▼
9. Remote exchanges code for GitHub access token (has client secret)
       │
       ▼
10. Remote creates JWT session token, encrypts with AES-256-GCM
       │
       ▼
11. Remote redirects to Local: http://localhost:53427/oauth/callback?handoff_id=...&tokens=...
       │
       ▼
12. Local server decrypts tokens, stores in OAuthCredentials (disk)
       │
       ▼
13. Local redirects frontend to /
       │
       ▼
14. Frontend polls GET /api/auth/status until logged_in: true
```

**Security**: Handoff IDs expire after 5 minutes, tokens encrypted in transit

### 4.2 Issue/PR Sync

**Local to Remote Sync**:

```
Local SQLite                Remote PostgreSQL
──────────────              ──────────────────
tasks                 --->  issues
workspaces           --->  workspaces
execution_processes  --->  (not synced)
merges               --->  pull_requests
```

**Sync Flow** (via MigrationService):
1. User triggers migration: POST /api/migration/start { organization_id, project_id }
2. Local server authenticates with Remote using stored JWT
3. For each task:
   - POST /v1/issues { title, description, project_id }
   - Store mapping in migration_state table { local_id, remote_id }
4. For each workspace:
   - POST /v1/workspaces { issue_id (from mapping), ... }
5. Real-time updates via Electric SQL (PostgreSQL replication)

### 4.3 Electric SQL Real-time Sync

**Purpose**: PostgreSQL to Frontend real-time data sync

**Architecture**:
```
PostgreSQL (Remote Server)
       │
       ▼
Electric replication log
       │
       ▼
Electric SQL Proxy (in Remote Server)
       │
       ▼
HTTP Shape Stream (long-polling)
       │
       ▼
Frontend Electric Client (frontend/src/lib/electric/)
       │
       ▼
Local IndexedDB cache + React state
```

**Proxy Endpoint**: `/v1/electric-proxy/*` (authenticated via JWT)

**Shape API**: Frontend subscribes to "shapes" (filtered views of tables)

**Example**:
```typescript
// Frontend subscribes to organization's issues
const issuesShape = await db.electric.syncShape({
  table: 'issues',
  where: `project_id = '${projectId}'`
});

// Automatic reactivity - UI updates when PostgreSQL changes
```

---

## 5. External Service Integrations

### 5.1 GitHub API Integration

**Three Integration Points**:

1. **OAuth Authentication**:
   - Remote server redirects to GitHub OAuth
   - Scopes: `repo`, `user:email`, `read:org`
   - Tokens stored encrypted in local OAuthCredentials

2. **GitHub CLI (gh) Integration**:
   - Local server shells out to `gh` CLI for PR operations
   - Commands: `gh pr create`, `gh pr view`, `gh pr comment`
   - Workspace-specific: runs in worktree directory

3. **GitHub App Webhooks** (Remote Server):
   - Endpoint: `/v1/github-app/webhook`
   - Events: PR opened, merged, closed, review requested
   - Updates PostgreSQL `pull_requests` table
   - Triggers Electric sync to frontend

**PR Monitoring**:
- PrMonitorService (local) polls every 60s
- Checks PR status via `gh pr view --json state,mergedAt`
- Updates local `merges` table with pr_status, pr_merged_at

### 5.2 Stripe Billing Integration

**Remote Server Only**:
- Endpoint: `/v1/billing/*`
- Stripe webhook handling: `/v1/billing/webhook`
- Events: `customer.subscription.created`, `customer.subscription.updated`, `invoice.paid`
- Stores billing state in PostgreSQL `subscriptions` table
- JWT-protected API for frontend billing portal

### 5.3 PostHog Analytics

**Local Server Integration**:
```rust
// AnalyticsService (crates/services/src/services/analytics.rs)
impl AnalyticsService {
    pub fn track_event(&self, user_id: &str, event_name: &str, properties: Option<Value>) {
        if !self.enabled { return; }

        let payload = json!({
            "api_key": self.api_key,
            "event": event_name,
            "distinct_id": user_id,
            "properties": properties
        });

        // Fire-and-forget HTTP POST to PostHog
        tokio::spawn(async move {
            let _ = reqwest::Client::new()
                .post(&format!("{}/capture/", self.endpoint))
                .json(&payload)
                .send()
                .await;
        });
    }
}
```

**Events Tracked**:
- `session_start` - Server startup
- `project_created` - Project creation (manual or auto)
- `workspace_created` - Workspace start
- `agent_execution_started` - Coding agent spawn
- `pr_created` - PR creation
- `merge_completed` - Branch merge

**Privacy**: User can opt-out via config, anonymous distinct_id used

### 5.4 Sentry Error Monitoring

**Initialization** (both local and remote):
```rust
// crates/utils/src/sentry.rs
pub fn init_once(source: SentrySource) {
    let _guard = sentry::init((
        std::env::var("SENTRY_DSN").ok(),
        sentry::ClientOptions {
            release: Some(env!("CARGO_PKG_VERSION").into()),
            environment: Some(match source {
                SentrySource::Backend => "backend".into(),
                SentrySource::Remote => "remote".into(),
            }),
            ..Default::default()
        }
    ));
}
```

**Scope Configuration**:
```rust
// After user authentication
deployment.update_sentry_scope().await; // Sets user context

sentry::configure_scope(|scope| {
    scope.set_user(Some(sentry::User {
        id: Some(user_id.to_string()),
        username: Some(github_username),
        email: Some(github_email),
        ..Default::default()
    }));
});
```

**Integration with Tracing**:
- `sentry_layer()` captures tracing errors as Sentry events
- Automatic breadcrumbs for all HTTP requests
- Panic handler captures crash reports

### 5.5 Cloudflare R2 Storage

**Purpose**: Binary distribution and artifact storage

**NPX CLI Flow**:
```
1. User runs: npx vibe-kanban
       │
       ▼
2. npx-cli/bin/cli.js detects platform (darwin, linux, win32)
       │
       ▼
3. Checks local cache: ~/.vibe-kanban/bin/{platform}-{version}
       │
       ▼
4. If missing, downloads from R2: https://r2-bucket.com/vibe-kanban/{version}/{platform}
       │
       ▼
5. Extracts binary to cache, makes executable
       │
       ▼
6. Spawns binary as child process
```

**CI Upload** (in `.github/workflows/pre-release.yml`):
```yaml
- name: Upload to R2
  run: |
    for artifact in binaries/*; do
      aws s3 cp $artifact s3://vibe-kanban-releases/$VERSION/$(basename $artifact) \
        --endpoint-url $R2_ENDPOINT
    done
```

---

## 6. Real-time Event Architecture

### 6.1 SQLite Hooks to MsgStore

**Event Registration** (`crates/local-deployment/src/lib.rs`):
```rust
impl LocalDeployment {
    pub async fn new() -> Result<Self, DeploymentError> {
        // ... other initialization ...

        let events = EventService::new();
        let db = DBService::new_with_after_connect({
            let events = events.clone();
            move |conn| {
                let events = events.clone();
                Box::pin(async move {
                    EventService::register_event_listener(conn, &events).await
                })
            }
        }).await?;

        // ...
    }
}
```

**Hook Implementation** (`crates/services/src/services/events.rs`):
```rust
pub async fn register_event_listener(
    conn: &mut SqliteConnection,
    events: &EventService,
) -> Result<(), sqlx::Error> {
    // Create trigger functions for each table
    for table in ["tasks", "workspaces", "execution_processes", "sessions", ...] {
        sqlx::query(&format!(
            "CREATE TRIGGER IF NOT EXISTS {table}_after_insert
             AFTER INSERT ON {table}
             BEGIN
                 SELECT event_notify('insert', '{table}', NEW.id);
             END"
        )).execute(conn).await?;

        sqlx::query(&format!(
            "CREATE TRIGGER IF NOT EXISTS {table}_after_update
             AFTER UPDATE ON {table}
             BEGIN
                 SELECT event_notify('update', '{table}', NEW.id);
             END"
        )).execute(conn).await?;
    }

    // Register UDF for event_notify
    conn.create_scalar_function("event_notify", 3, true, |ctx| {
        let op = ctx.get::<String>(0)?;
        let table = ctx.get::<String>(1)?;
        let id = ctx.get::<String>(2)?;

        // Generate JSON Patch based on operation
        let patch = generate_patch(&op, &table, &id)?;

        // Push to MsgStore
        events.msg_store().push_patch(patch);

        Ok(())
    })?;

    Ok(())
}
```

### 6.2 JSON Patch-based Incremental Updates

**Patch Format** (RFC 6902):
```json
[
  { "op": "add", "path": "/tasks/0", "value": { "id": "...", "title": "..." } },
  { "op": "replace", "path": "/tasks/0/status", "value": "InProgress" },
  { "op": "remove", "path": "/tasks/1" }
]
```

**Frontend Application**:
```typescript
// Frontend EventContext applies patches to Zustand stores
const eventSource = new EventSource('/api/events');

eventSource.onmessage = (event) => {
  const msg = JSON.parse(event.data);

  if (msg.type === 'JsonPatch') {
    const patch = msg.patch;

    // Apply patch to appropriate store
    if (patch.path.startsWith('/tasks/')) {
      useTaskStore.getState().applyPatch(patch);
    } else if (patch.path.startsWith('/workspaces/')) {
      useWorkspaceStore.getState().applyPatch(patch);
    }
  }
};
```

**Benefits**:
- Minimal bandwidth (only changes sent)
- No polling required
- Consistent state across tabs
- Automatic conflict resolution

### 6.3 Event Types and Channels

**LogMsg Variants** (`crates/utils/src/log_msg.rs`):
```rust
pub enum LogMsg {
    Stdout(String),
    Stderr(String),
    JsonPatch(json_patch::Patch),
    SessionId(String),
    MessageId(String),
    Finished,
}
```

**SSE Event Conversion**:
```rust
impl LogMsg {
    pub fn to_sse_event(&self) -> Event {
        match self {
            LogMsg::Stdout(s) => Event::default().event("stdout").data(s),
            LogMsg::Stderr(s) => Event::default().event("stderr").data(s),
            LogMsg::JsonPatch(p) => Event::default().event("patch").json_data(p).unwrap(),
            LogMsg::SessionId(id) => Event::default().event("session_id").data(id),
            LogMsg::MessageId(id) => Event::default().event("message_id").data(id),
            LogMsg::Finished => Event::default().event("finished").data(""),
        }
    }
}
```

---

## 7. AI Agent Integration

### 7.1 Executor Spawning

**Agent Lifecycle**:
```
1. Frontend: POST /api/sessions { workspace_id, executor: "ClaudeCode" }
       │
       ▼
2. SessionService::create_session
       │
       ▼
3. ContainerService::spawn_executor
       │
       ▼
4. Executor::spawn (trait method)
       │
       ├──> ClaudeCodeExecutor::spawn
       │    └──> tokio::process::Command::new("claude")
       │              .arg("--chat")
       │              .current_dir(workspace_path)
       │              .stdin(Stdio::piped())
       │              .stdout(Stdio::piped())
       │              .stderr(Stdio::piped())
       │              .spawn()
       │
       ▼
5. Child process running in workspace worktree
       │
       ├──> stdin: User messages (via follow-up API)
       ├──> stdout: JSONL logs
       └──> stderr: Error messages
              │
              ▼
6. LogParser reads stdout line-by-line
       │
       ▼
7. Normalized logs pushed to MsgStore
       │
       ▼
8. SSE stream to frontend: /api/execution-processes/:id/stream
```

**Executor Trait** (`crates/executors/src/lib.rs`):
```rust
#[async_trait]
pub trait StandardCodingAgentExecutor {
    async fn spawn(
        &self,
        context: ExecutorContext,
        action: ExecutorAction,
    ) -> Result<ExecutionProcess, ExecutorError>;

    async fn spawn_follow_up(
        &self,
        context: ExecutorContext,
        session_id: String,
        message: String,
    ) -> Result<ExecutionProcess, ExecutorError>;

    async fn spawn_review(
        &self,
        context: ExecutorContext,
        files: Vec<String>,
    ) -> Result<ExecutionProcess, ExecutorError>;

    fn normalize_logs(&self, raw_logs: Vec<String>) -> Vec<LogMsg>;

    fn available_slash_commands(&self) -> Vec<SlashCommand>;
}
```

**Supported Agents** (9 implementations):
- ClaudeCode (`claude --chat`)
- Amp (`amp`)
- Gemini (`gemini`)
- Codex (`openai codex`)
- Cursor (`cursor-agent`)
- Opencode (`opencode`)
- QwenCode (`qwen-code`)
- Copilot (`gh copilot`)
- Droid (`droid`)

### 7.2 JSONL Log Streaming

**Log Format** (Agent-specific, normalized by executor):
```jsonl
{"type":"tool_use","tool":"read_file","args":{"path":"src/main.rs"}}
{"type":"tool_result","tool":"read_file","content":"..."}
{"type":"message","role":"assistant","content":"I'll update the file..."}
{"type":"approval_request","tool_call_id":"123","tool":"write_file","args":{...}}
```

**Streaming Flow**:
```
Agent stdout (JSONL)
       │
       ▼
LogParser::parse_line (crates/executors/src/logs/parser.rs)
       │
       ├──> Parses JSON
       ├──> Extracts tool calls
       ├──> Detects approval requests
       └──> Normalizes format
              │
              ▼
MsgStore::push(LogMsg::Stdout(normalized_json))
       │
       ▼
SSE Stream: /api/execution-processes/:id/stream
       │
       ▼
Frontend: NormalizedConversation component
       │
       ▼
Renders conversation with tool calls, approvals, etc.
```

**File Watching** (for agents that write to log files):
```rust
// crates/executors/src/logs/streaming.rs
pub async fn stream_log_file(
    log_path: PathBuf,
    msg_store: Arc<MsgStore>,
) -> Result<(), std::io::Error> {
    let mut watcher = notify::watcher(tx, Duration::from_millis(100))?;
    watcher.watch(&log_path, RecursiveMode::NonRecursive)?;

    let mut file = File::open(&log_path)?;
    let mut position = 0;

    loop {
        tokio::select! {
            _ = rx.recv() => {
                // File changed, read new lines
                file.seek(SeekFrom::Start(position))?;
                let mut reader = BufReader::new(&file);

                for line in reader.lines() {
                    let line = line?;
                    position += line.len() + 1; // +1 for newline

                    let msg = parse_log_line(&line);
                    msg_store.push(msg);
                }
            }
            _ = stop_signal.recv() => break,
        }
    }

    Ok(())
}
```

### 7.3 Tool Call Approval Flow

**Purpose**: User must approve destructive operations (file writes, shell commands)

**Flow**:
```
1. Agent requests approval (in JSONL log):
   {"type":"approval_request","tool_call_id":"abc123","tool":"write_file","args":{"path":"src/main.rs","content":"..."}}
       │
       ▼
2. LogParser detects approval_request type
       │
       ▼
3. Approvals::create_pending_approval
   - Stores in DashMap<tool_call_id, PendingApproval>
   - Creates oneshot channel for response
       │
       ▼
4. SSE event sent to frontend with approval request
       │
       ▼
5. Frontend renders approval dialog with tool details
       │
       ▼
6. User clicks Approve/Reject
       │
       ▼
7. POST /api/approvals/:tool_call_id/respond { approved: true }
       │
       ▼
8. Approvals::respond
   - Finds PendingApproval in DashMap
   - Sends response via oneshot channel
   - Agent unblocks and proceeds
       │
       ▼
9. Agent continues execution or aborts
```

**Approval Storage**:
```rust
pub struct Approvals {
    pending: Arc<DashMap<String, PendingApproval>>,
}

struct PendingApproval {
    tool_call_id: String,
    tool: String,
    args: Value,
    sender: oneshot::Sender<ApprovalResponse>,
    created_at: Instant,
}
```

### 7.4 MCP (Model Context Protocol) Server

**Purpose**: Expose Vibe Kanban functionality as MCP tools for agents

**Implementation** (`crates/server/src/mcp/mod.rs`):
```rust
pub async fn start_mcp_server(deployment: LocalDeployment) -> Result<(), Error> {
    let server = rmcp::Server::new()
        .with_tool("list_projects", |args| {
            let deployment = deployment.clone();
            async move {
                let projects = Project::list(&deployment.db().pool).await?;
                Ok(serde_json::to_value(projects)?)
            }
        })
        .with_tool("create_workspace", |args| {
            let deployment = deployment.clone();
            async move {
                let workspace = deployment.container()
                    .create_workspace(args.task_id, args.repos)
                    .await?;
                Ok(serde_json::to_value(workspace)?)
            }
        })
        .with_tool("start_execution", |args| {
            let deployment = deployment.clone();
            async move {
                let process = deployment.container()
                    .spawn_executor(args.workspace_id, args.executor, args.message)
                    .await?;
                Ok(serde_json::to_value(process)?)
            }
        });

    server.listen("127.0.0.1:7777").await?;
    Ok(())
}
```

**Available Tools**:
- `list_projects` - List all projects
- `create_workspace` - Create workspace for task
- `start_execution` - Start coding agent
- `get_workspace_status` - Check workspace state
- `read_file` - Read file from workspace
- `write_file` - Write file to workspace

---

## 8. Build-time Integration

### 8.1 ts-rs Type Generation Flow

**Trigger**: Pre-build step in CI or manual `cargo run --bin generate_types`

**Process**:
```
1. Rust compiler collects all #[derive(TS)] types
       │
       ▼
2. ts-rs proc macro generates TypeScript definitions
       │
       ▼
3. Writes to shared/types.ts (local server types)
       │
       ▼
4. Writes to shared/remote-types.ts (remote server types)
       │
       ▼
5. TypeScript compiler type-checks frontend
       │
       ▼
6. Build fails if frontend uses types incorrectly
```

**Example Rust Type**:
```rust
#[derive(Debug, Clone, Serialize, Deserialize, TS)]
#[ts(export, export_to = "../../../shared/types.ts")]
pub struct CreateTask {
    pub title: String,
    pub description: Option<String>,
    pub project_id: Uuid,
}
```

**Generated TypeScript**:
```typescript
export interface CreateTask {
    title: string;
    description?: string;
    project_id: string; // Uuid mapped to string
}
```

**Type Mappings**:
- `Uuid` -> `string`
- `DateTime<Utc>` -> `string` (ISO 8601)
- `Option<T>` -> `T | undefined`
- `Vec<T>` -> `T[]`
- `HashMap<K, V>` -> `Record<K, V>`

### 8.2 rust-embed (Frontend Embedding)

**Purpose**: Embed frontend build artifacts into Rust binary

**Configuration** (`crates/server/src/lib.rs`):
```rust
#[derive(RustEmbed)]
#[folder = "../../frontend/dist/"]
struct FrontendAssets;

pub fn serve_frontend() -> Router {
    Router::new()
        .fallback(|uri: Uri| async move {
            let path = uri.path().trim_start_matches('/');

            // Try to serve file from embedded assets
            if let Some(content) = FrontendAssets::get(path) {
                let mime = mime_guess::from_path(path)
                    .first_or_octet_stream();

                return Response::builder()
                    .header("Content-Type", mime.as_ref())
                    .body(Body::from(content.data))
                    .unwrap();
            }

            // Fallback to index.html for SPA routing
            let index = FrontendAssets::get("index.html").unwrap();
            Response::builder()
                .header("Content-Type", "text/html")
                .body(Body::from(index.data))
                .unwrap()
        })
}
```

**Build Process**:
```
1. Frontend build: npm run build (in frontend/)
   - Vite bundles React SPA
   - Output: frontend/dist/
       │
       ▼
2. Rust build: cargo build --release
   - rust-embed reads frontend/dist/
   - Embeds all files as &[u8] in binary
       │
       ▼
3. Single binary with embedded frontend
   - No separate static file server needed
   - Deployed as single executable
```

**Benefits**:
- Single binary distribution
- No asset deployment complexity
- Immediate frontend updates (just rebuild)
- Consistent versioning (frontend + backend in lockstep)

### 8.3 CI/CD Pipeline Integration

**GitHub Actions Workflow** (`.github/workflows/pre-release.yml`):

```yaml
name: Pre-release Build

on:
  push:
    tags: ['v*']

jobs:
  build-matrix:
    strategy:
      matrix:
        include:
          - os: macos-14
            target: aarch64-apple-darwin
          - os: macos-13
            target: x86_64-apple-darwin
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
          - os: ubuntu-latest
            target: aarch64-unknown-linux-gnu
          - os: windows-latest
            target: x86_64-pc-windows-msvc
          - os: windows-latest
            target: aarch64-pc-windows-msvc

    steps:
      # 1. Generate TypeScript types
      - name: Generate types
        run: cargo run --bin generate_types

      # 2. Build frontend
      - name: Install Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 24

      - name: Install pnpm
        uses: pnpm/action-setup@v4

      - name: Build frontend
        run: |
          cd frontend
          pnpm install --frozen-lockfile
          pnpm build

      # 3. Build Rust binary (embeds frontend)
      - name: Build Rust
        run: cargo build --release --target ${{ matrix.target }}

      # 4. Sign macOS binary
      - name: Sign macOS binary
        if: runner.os == 'macOS'
        run: |
          codesign --force --sign - \
            --options runtime \
            target/${{ matrix.target }}/release/vibe-kanban

      # 5. Upload to R2
      - name: Upload to Cloudflare R2
        run: |
          aws s3 cp target/${{ matrix.target }}/release/vibe-kanban \
            s3://vibe-kanban-releases/${{ github.ref_name }}/${{ matrix.target }}/vibe-kanban \
            --endpoint-url ${{ secrets.R2_ENDPOINT }}
```

**Build Dependencies**:
1. **Type generation** must complete before frontend build
2. **Frontend build** must complete before Rust build
3. **Rust build** embeds frontend artifacts
4. **Platform signing** (macOS) happens post-build
5. **R2 upload** happens after signing

**Deployment Flow**:
```
GitHub Tag Push (v1.2.3)
       │
       ▼
CI builds 6 platform binaries (with embedded frontend)
       │
       ▼
Uploads to R2: s3://vibe-kanban-releases/v1.2.3/{platform}/vibe-kanban
       │
       ▼
npm publish: vibe-kanban@1.2.3 (npx-cli wrapper)
       │
       ▼
User runs: npx vibe-kanban@1.2.3
       │
       ▼
NPX CLI downloads correct platform binary from R2
       │
       ▼
Binary starts server with embedded frontend
```

---

## Integration Patterns Summary

| Pattern | Implementation | Benefits |
|---------|----------------|----------|
| **Service Locator** | Deployment trait | Testability, swappable implementations |
| **Dependency Injection** | LocalDeployment struct | Centralized service management |
| **Event Sourcing Lite** | SQLite hooks -> MsgStore | Real-time UI updates, audit trail |
| **Worktree Isolation** | Git worktrees per workspace | Parallel agent execution |
| **JSON Patch Streaming** | MsgStore -> SSE | Minimal bandwidth, incremental updates |
| **Type Generation** | ts-rs | Compile-time type safety across languages |
| **Asset Embedding** | rust-embed | Single binary distribution |
| **OAuth Delegation** | Handoff to remote server | Secure credential handling |
| **Child Process Orchestration** | tokio::process | Agent lifecycle management |
| **WebSocket Multiplexing** | Axum WebSocket handlers | Bidirectional real-time comms |

---

*Generated by BMAD Document Project Workflow v1.2.0 (Deep Scan)*
